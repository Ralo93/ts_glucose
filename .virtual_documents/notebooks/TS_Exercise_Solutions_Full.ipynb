!pip install pandas numpy matplotlib statsmodels


!pip install pmdarima darts tbats





# https://drive.google.com/file/d/1k2qILdyzADkZBH78bYfiuLqy3sqVLFCB/view?usp=drive_link
!gdown 1k2qILdyzADkZBH78bYfiuLqy3sqVLFCB





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

df = pd.read_csv('sales_data.csv')
df.set_index('date', inplace=True)
df





sales = df[['sold']]
sales.plot()








from statsmodels.tsa.stattools import adfuller

def adf_test(timeseries, regression='c'):
    print("Results of Dickey-Fuller Test:")
    dftest = adfuller(timeseries, autolag="AIC", regression=regression)
    dfoutput = pd.Series(
        dftest[0:4],
        index=[
            "Test Statistic",
            "p-value",
            "#Lags Used",
            "Number of Observations Used",
        ],
    )
    for key, value in dftest[4].items():
        dfoutput["Critical Value (%s)" % key] = value
    print(dfoutput)


adf_test(sales.values)








from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

plot_acf(sales.values, lags=23);








from pmdarima import model_selection

train, test = model_selection.train_test_split(sales, train_size=len(sales)-28)





from pmdarima.arima import ADFTest

ADFTest().should_diff(train)





import pmdarima as pm

d = 0
D = 0
seasonal = True
m = 7

# Fit a simple auto_arima model
arima = pm.auto_arima(train, error_action='ignore', trace=True, suppress_warnings=True, maxiter=5,
                      d=d, D=D, seasonal=seasonal, m=m)





fig, ax = plt.subplots(1, 1)
ax.plot(train.index, train, label='Actual')
ax.plot(train.index, arima.fittedvalues(), label='Fitted', linestyle='--')
ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))
plt.xticks(rotation=70)
plt.legend()





fig, ax = plt.subplots(1, 1, figsize=(4, 4))
ax.scatter(train, arima.fittedvalues(), alpha=0.5)
ax.plot([0, 2000], [0, 2000], linestyle='--')
ax.set_xlim([0, 2000])
ax.set_xlabel('Actual')
ax.set_ylim([0, 2000])
ax.set_ylabel('Forecast')





def mape(y_true, y_pred):
    actual = y_true.copy()
    forecast = y_pred.copy()
    if isinstance(actual, (pd.Series, pd.DataFrame)):
        actual = actual.values
    if isinstance(forecast, (pd.Series, pd.DataFrame)):
        forecast = forecast.values
    if isinstance(actual, np.ndarray):
        actual = actual.squeeze()
    if isinstance(forecast, np.ndarray):
        forecast = forecast.squeeze()

    # Ensure the arrays have the same length
    assert len(actual) == len(forecast), "Length of actual and forecast arrays should be the same"

    # Avoid division by zero by replacing zeros in the 'actual' array with a small number
    actual = np.where(actual == 0, 1e-10, actual)

    # Calculate MAPE for each data point
    mape_values = np.abs((actual - forecast) / actual)

    # Calculate the mean MAPE value
    mean_mape = np.mean(mape_values) * 100  # Multiply by 100 to get percentage

    return mean_mape

def smape(y_true, y_pred):
    actual = y_true.copy()
    forecast = y_pred.copy()
    if isinstance(actual, (pd.Series, pd.DataFrame)):
        actual = actual.values
    if isinstance(forecast, (pd.Series, pd.DataFrame)):
        forecast = forecast.values
    if isinstance(actual, np.ndarray):
        actual = actual.squeeze()
    if isinstance(forecast, np.ndarray):
        forecast = forecast.squeeze()

    # Ensure the arrays have the same length
    assert len(actual) == len(forecast), "Length of actual and forecast arrays should be the same"

    # Calculate SMAPE for each data point
    smape_values = 2 * np.abs(actual - forecast) / (np.abs(actual) + np.abs(forecast))

    # Calculate the mean SMAPE value
    mean_smape = np.mean(smape_values) * 100  # Multiply by 100 to get percentage

    return mean_smape


mape(train, arima.fittedvalues()),smape(train, arima.fittedvalues())





x = np.arange(test.shape[0])
plt.plot(test.index, test, label='Actual')
plt.plot(test.index, arima.predict(n_periods=len(x)), label='Forecast', linestyle='--', c='r')
plt.xticks(rotation=70)
plt.legend()











from statsmodels.tsa.api import SimpleExpSmoothing

ses = SimpleExpSmoothing(train, initialization_method='estimated').fit(optimized=True)
ses.params





fig, ax = plt.subplots(1, 1)
ax.plot(train.index, train, label='Sales')
ax.plot(train.index, ses.fittedvalues, linestyle='--', label='Fitted Values')
ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))
plt.xticks(rotation=70)
ax.legend()





fig, ax = plt.subplots(1, 1, figsize=(4, 4))
ax.scatter(train, ses.fittedvalues, alpha=0.5)
ax.plot([0, 2000], [0, 2000], linestyle='--')
ax.set_xlim([0, 2000])
ax.set_xlabel('Actual')
ax.set_ylim([0, 2000])
ax.set_ylabel('Forecast')





mape(train, ses.fittedvalues), smape(train, ses.fittedvalues),





plt.plot(test.index, test, label='Sales')
plt.plot(test.index, ses.forecast(28), linestyle='--', c='r', label='Forecast')
plt.xticks(rotation=70)
plt.legend()








from statsmodels.tsa.exponential_smoothing.ets import ETSModel

model = ETSModel(train.squeeze(), initialization_method='estimated')
fit = model.fit(optimized=True)





pred = fit.get_prediction(start="2017-04-03", end="2017-04-30")
pred





pred.predicted_mean





alpha = 0.05
df = pred.summary_frame(alpha=alpha)
df





simulated = fit.simulate(anchor="end", nsimulations=28, repetitions=100)
simulated





for i in range(simulated.shape[1]):
    simulated.iloc[:, i].plot(label="_", color="gray", alpha=0.1)

df["mean"].plot(label="mean prediction", linestyle='--', c='r')
df["pi_lower"].plot(linestyle="--", c='b', label="95% interval")
df["pi_upper"].plot(linestyle="--", c='b', label="_")
plt.plot(df.index, test, label='Sales')
plt.legend()





from statsmodels.tsa.api import ExponentialSmoothing

seasonal_periods = 7

holt_winters = ExponentialSmoothing(
    train.squeeze(),
    seasonal_periods=seasonal_periods,
    trend="add",
    seasonal="add",
    initialization_method="estimated",
).fit(optimized=True)





fig, ax = plt.subplots(1, 1)
ax.plot(train.index, train, label='Sales')
ax.plot(train.index, holt_winters.fittedvalues, linestyle='--', label='Fitted Values')
ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))
plt.xticks(rotation=70)
ax.legend()


fig, ax = plt.subplots(1, 1, figsize=(4, 4))
ax.scatter(train, holt_winters.fittedvalues, alpha=0.5)
ax.plot([0, 2000], [0, 2000], linestyle='--')
ax.set_xlim([0, 2000])
ax.set_xlabel('Actual')
ax.set_ylim([0, 2000])
ax.set_ylabel('Forecast')





mape(train, holt_winters.fittedvalues), smape(train, holt_winters.fittedvalues)





fc_values = holt_winters.forecast(28)

plt.plot(test.index, test, label='Sales')
plt.plot(test.index, fc_values, linestyle='--', c='r', label='Fitted Values')
plt.xticks(rotation=70)
plt.legend()





from statsmodels.tsa.exponential_smoothing.ets import ETSModel

seasonal_periods = 7

model = ETSModel(
    train.squeeze(),
    seasonal_periods=seasonal_periods,
    trend="add",
    seasonal="add",
    initialization_method="estimated"
)
fit = model.fit(optimized=True)





pred = fit.get_prediction(start="2017-04-03", end="2017-04-30")


fit_vals = pred.predicted_mean

plt.plot(test.index, test, label='Sales')
plt.plot(test.index, fit_vals, linestyle='--', c='r', label='Fitted Values')
plt.xticks(rotation=70)
plt.legend()





df = pred.summary_frame(alpha=0.05)
simulated = fit.simulate(anchor="end", nsimulations=28, repetitions=100)


for i in range(simulated.shape[1]):
    simulated.iloc[:, i].plot(label="_", color="gray", alpha=0.05)

plt.plot(df.index, test, label='Sales')
df["mean"].plot(label="mean prediction", linestyle='--', c='r')
df["pi_lower"].plot(linestyle="--", color="b", label="95% interval")
df["pi_upper"].plot(linestyle="--", color="b", label="_")
plt.legend()








from statsmodels.tsa.seasonal import seasonal_decompose

result = seasonal_decompose(train, model='additive', period=7)
result.plot();


df = pd.concat([result.trend, result.seasonal, result.resid], axis=1).tail(20)
df





# Trend
strength_trend = max(0, 1-df['resid'].var()/(df['resid']+df['trend']).var())

# Season
strength_season = max(0, 1-df['resid'].var()/(df['resid']+df['seasonal']).var())

strength_trend, strength_season





from statsmodels.tsa.seasonal import STL

stl = STL(train, period=7, seasonal=15)
res = stl.fit()
res.plot();





df = pd.concat([res.trend, res.seasonal, res.resid], axis=1).tail(20)
df





# Trend
strength_trend = max(0, 1-df['resid'].var()/(df['resid']+df['trend']).var())

# Season
strength_season = max(0, 1-df['resid'].var()/(df['resid']+df['season']).var())

strength_trend, strength_season





from statsmodels.tsa.api import STLForecast
from statsmodels.tsa.statespace import exponential_smoothing

index = pd.date_range(train.index[0], periods=len(train), freq='D')
train.index = index

ES = exponential_smoothing.ExponentialSmoothing
config = {"trend": False, "initialization_method": "estimated"}
period = 7
s_window = 15

stlf = STLForecast(train, ES, model_kwargs=config, period=period, seasonal=s_window)
resf = stlf.fit()
forecasts = resf.forecast(28)


plt.plot(test.index, test, label='Sales')
plt.plot(test.index, forecasts, label='Forecast', c='r', linestyle='--')
plt.xticks(rotation=70)
plt.legend()











index = pd.date_range('2015-01-01', periods=823, freq='D')
train.index = index

train['woy'] = train.index.isocalendar().week.astype(int)
train['wday'] = train.index.weekday
train['t'] = pd.RangeIndex(len(train))





import statsmodels.formula.api as smf

# https://www.statsmodels.org/stable/example_formulas.html
mod_dummy = smf.ols("sold ~ t + C(woy) + C(wday)", data=train).fit()
mod_dummy.summary()





pred = mod_dummy.predict(train[['t', 'woy', 'wday']])
pred


train['sold'].plot(label='Data')
pred.plot(label='Fitted', linestyle='--')
plt.legend()





mape(train['sold'], pred), smape(train['sold'], pred)





index = pd.date_range('2017-04-03', periods=28, freq='D')
test.index = index
test['woy'] = test.index.isocalendar().week.astype(int)
test['wday'] = test.index.weekday
test['t'] = pd.RangeIndex(len(test))+len(train)





fcast = mod_dummy.predict(test[['t', 'woy', 'wday']])


test['sold'].plot(label='Data')
fcast.plot(label='Forecast', linestyle='--', c='r')
plt.legend()








from darts import TimeSeries
new_y = train['sold'].copy()
ts_y = TimeSeries.from_series(new_y)
ts_y


from darts.models import LinearRegressionModel

model = LinearRegressionModel(
    lags=[-1, -7, -28],
)

model.fit(ts_y)





model.model


model.model.coef_





fittedvals = model.historical_forecasts(ts_y)


ts_y.plot(label='Data')
fittedvals.plot(label='Fitted', linestyle='--', c='orange')





mape(ts_y.values()[30:], fittedvals.values()), smape(ts_y.values()[30:], fittedvals.values())





fcast = model.predict(28)
fcast


TimeSeries.from_series(test['sold']).plot(label='Actual')
fcast.plot(label='Forecast', c='r', linestyle='--')











from darts.utils.timeseries_generation import holidays_timeseries

def get_holiday(idx):
    return holidays_timeseries(idx, country_code='DE')





future_cov = get_holiday(train.index.union(test.index))
future_cov





from darts.utils.timeseries_generation import datetime_attribute_timeseries

time_index = train.index.union(test.index)

month = datetime_attribute_timeseries(time_index=time_index, attribute="month")
weekday = datetime_attribute_timeseries(time_index=time_index, attribute="dayofweek")
weekofyear = datetime_attribute_timeseries(time_index=time_index, attribute="weekofyear")
future_cov = future_cov.stack(month).stack(weekday).stack(weekofyear)
future_cov = future_cov.astype(np.float32)
future_cov





from darts.models import RandomForest

model2 = RandomForest(
    lags=[-1, -7, -28],
    lags_future_covariates=[0],
    output_chunk_length=7,
    n_estimators=200,
    max_depth=5,
    criterion="absolute_error",
)





model2.fit(ts_y, future_covariates=future_cov)





fittedvals = model2.historical_forecasts(ts_y, retrain=False)


ts_y.plot(label='Data')
fittedvals.plot(label='Fitted', linestyle='--', c='orange')





mape(ts_y.values()[28:], fittedvals.values()), smape(ts_y.values()[28:], fittedvals.values())





model2.lagged_feature_names


dict(zip(model2.lagged_feature_names, model2.model.feature_importances_))





pred2 = model2.predict(28)


TimeSeries.from_series(test['sold']).plot(label='Actual')
pred2.plot(label='Forecast', c='r', linestyle='--')








res7 = model2.backtest(ts_y, future_covariates=future_cov,
                       start=None, forecast_horizon=7, stride=7, train_length=750, reduction=None)
res28 = model2.backtest(ts_y, future_covariates=future_cov,
                        start=None, forecast_horizon=28, stride=7, train_length=750, reduction=None)


print(res7)


print(res28)





from tbats import TBATS

if __name__ == '__main__':
    estimator = TBATS(seasonal_periods=[7, 365.25], n_jobs=1)


# Fit model
fitted_model = estimator.fit(train['sold'])

# Summarize fitted model
print(fitted_model.summary())


ax = train['sold'].plot(label='Data')
pred = pd.Series(fitted_model.y_hat, index=train['sold'].index)
ax.plot(pred, label='Fitted', linestyle='--')
plt.legend()


mape(train['sold'], pred), smape(train['sold'], pred)


# Forecast 28 steps ahead
fcast = fitted_model.forecast(steps=28)
fcast


ax = test['sold'].plot(label='Data')
ax.plot(pd.Series(fcast, index=test['sold'].index), label='Forecast', linestyle='--', c='r')
plt.legend()
