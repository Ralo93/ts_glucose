import requests
from io import BytesIO
from zipfile import ZipFile
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


p12 = pd.read_csv(r"../data/interim/p12_clean.csv", low_memory=False)


first_day_df = p12[0:160]
first_day_df


#first_day_df.set_index('time: 0', inplace=True)


first_day_df.set_index('time', inplace=True)


first_day_df


transformed = transform_into_ts(first_day_df)


df = transformed





import pandas as pd

def remove_redundancy(df):
    """
    Function to remove redundancy in a DataFrame by ensuring unique 'time' values 
    and preserving as much information in the 'bg' column as possible.

    Parameters:
    df (DataFrame): The input DataFrame containing 'time' and 'bg' columns.

    Returns:
    DataFrame: The processed DataFrame with unique 'time' values and cleaned 'bg' values.
    """
    # Sort the DataFrame by time to ensure chronological order
    df = df.sort_values(by='time')

    # Drop duplicate 'time' entries, prioritizing non-NaN values in 'bg'
    df = df.drop_duplicates(subset='time', keep='first')

    # Forward-fill NaN values in 'bg' to preserve as much data as possible
    df['bg'] = df['bg'].fillna(method='ffill')

    # Alternatively, you can use backward fill if desired (use 'bfill' instead of 'ffill')
    # df['bg'] = df['bg'].fillna(method='bfill')

    # Reset the index after removing duplicates
    df.reset_index(drop=True, inplace=True)

    return df

# Example usage:
# final_df = remove_redundancy(df)
# print(final_df)



import pandas as pd
from datetime import timedelta

def transform_into_ts(df):
    # Initialize an empty DataFrame that will hold all the concatenated results
    final_df = pd.DataFrame(columns=['time', 'bg'])

    # Loop through each row in the DataFrame
    for _, row in df.iterrows():  # Use iterrows() to iterate through DataFrame rows
        # Ensure 'time' is a datetime object
        start_time = pd.to_datetime(row['time'])

        # Extract the first value (assuming the first value is associated with 'bg-0:00')
        first_value = row['bg-0:00']

        # Create a DataFrame for the first entry
        new_row = pd.DataFrame({'time': [start_time], 'bg': [first_value]})
        
        # Concatenate the first row into the final DataFrame
        final_df = pd.concat([final_df, new_row], ignore_index=True)

        # Iterate over the remaining columns (assuming bg columns start at index 2)
        for i, column in enumerate(reversed(row.index[2:-2])):  # Skip the last two columns if needed
            value = row[column]  # Get the value for the current column

            # Create the time for each 'bg-*' column by adding a time delta (adjust as needed)
            time_delta = timedelta(minutes=-5 * (i + 1))  # Example: 5-minute intervals
            new_time = start_time + time_delta  # Adjust time based on column

            # Create a new row for the time and value
            new_row = pd.DataFrame({'time': [new_time], 'bg': [value]})
            
            # Concatenate the new row into the final DataFrame
            final_df = pd.concat([final_df, new_row], ignore_index=True)

    #Set 'time' as the index and sort by time
    #final_df.set_index('time', inplace=True)
    #final_df.sort_index(inplace=True)

    return final_df

# Example usage with a DataFrame:
# Assuming you have a DataFrame 'df' with rows of data
# final_df = transform_into_ts(df)
# print(final_df)



cleaned_df = remove_redundancy(df)
print(cleaned_df)


import pandas as pd

def verify_data_preservation(original_df, cleaned_df):
    """
    Function to verify that information in the cleaned DataFrame is preserved from the original DataFrame.
    
    Parameters:
    original_df (DataFrame): The original DataFrame before cleaning.
    cleaned_df (DataFrame): The cleaned DataFrame after removing redundancy.
    
    Returns:
    bool: True if data is preserved, False otherwise.
    """
    # Sort both DataFrames by 'time' to ensure consistency in comparison
    original_df_sorted = original_df.sort_values(by='time').reset_index(drop=True)
    cleaned_df_sorted = cleaned_df.sort_values(by='time').reset_index(drop=True)

    # Check if all time values in cleaned_df are in original_df
    time_check = cleaned_df_sorted['time'].isin(original_df_sorted['time']).all()
    
    # Check if bg values for corresponding time are the same (after NaN filling in cleaned_df)
    bg_check = True
    for time in cleaned_df_sorted['time']:
        original_bg = original_df_sorted.loc[original_df_sorted['time'] == time, 'bg'].values
        cleaned_bg = cleaned_df_sorted.loc[cleaned_df_sorted['time'] == time, 'bg'].values

        # If the cleaned bg value is NaN in the original, or if they match, continue
        if pd.isna(original_bg).all() or pd.isna(cleaned_bg).all():
            continue
        
        # Compare the bg values only when not NaN
        if not (original_bg == cleaned_bg).all():
            bg_check = False
            break

    # Return True only if both the time and bg checks passed
    return time_check and bg_check

# Example usage
# original_df = pd.DataFrame(...)  # Your original DataFrame
# cleaned_df = remove_redundancy(original_df)
#is_preserved = verify_data_preservation(original_df, cleaned_df)
# print(is_preserved)



is_preserved = verify_data_preservation(df, cleaned_df)
print(is_preserved)


cleaned_df


cleaned_df.to_csv('../data/processed/p12_first_day.csv', index=False)  # Save to a CSV file



