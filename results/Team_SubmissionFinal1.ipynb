{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e50cd42-39f4-44b5-8926-40eba1f90f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c236a90-2028-47f4-8450-d2b427032267",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/interim/all_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2351f75-171d-4b29-a624-946ae39bba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9746b4e-d7b1-4b1d-a9a8-47fee0ecfc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.height_percentage.value_counts()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1506457-9bd2-4566-944f-7d22b86c57bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id',\n",
       "       'count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage',\n",
       "       'land_surface_condition', 'foundation_type', 'roof_type',\n",
       "       'ground_floor_type', 'other_floor_type', 'position',\n",
       "       'plan_configuration', 'has_superstructure_adobe_mud',\n",
       "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
       "       'has_superstructure_cement_mortar_stone',\n",
       "       'has_superstructure_mud_mortar_brick',\n",
       "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
       "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
       "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
       "       'legal_ownership_status', 'count_families', 'has_secondary_use',\n",
       "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
       "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
       "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
       "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
       "       'has_secondary_use_use_police', 'has_secondary_use_other',\n",
       "       'damage_grade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "a6045598-191a-4ff6-8553-67ed7d988f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.0\n",
      "(260601, 39)\n",
      "(252139, 39)\n"
     ]
    }
   ],
   "source": [
    "pct = np.percentile(data.loc[:, 'area_percentage'].fillna(np.mean(data.loc[:, 'area_percentage'])), 97)\n",
    "print(pct)\n",
    "print(data.shape)\n",
    "data = data.loc[data.loc[:, 'area_percentage'] < pct]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "93b6e2dc-0f06-4402-ac5c-39f8e34bf7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "(252139, 39)\n",
      "(240799, 39)\n"
     ]
    }
   ],
   "source": [
    "pct = np.percentile(data.loc[:, 'height_percentage'].fillna(np.mean(data.loc[:, 'height_percentage'])), 97)\n",
    "print(pct)\n",
    "print(data.shape)\n",
    "data = data.loc[data.loc[:, 'height_percentage'] < pct]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3225b70-c2cc-4128-b38b-7ea6d247c837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "dce0615b-14b6-4abb-9693-594170945b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class GeoInteractionTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to create geo interaction terms by concatenating the geo-level IDs.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_new = X.copy()\n",
    "        # Concatenate geo_level_1_id, geo_level_2_id, and geo_level_3_id\n",
    "        X_new['geo1_geo2'] = X_new['geo_level_1_id'].astype(str) + '_' + X_new['geo_level_2_id'].astype(str)\n",
    "        X_new['geo1_geo3'] = X_new['geo_level_1_id'].astype(str) + '_' + X_new['geo_level_3_id'].astype(str)\n",
    "        X_new['geo2_geo3'] = X_new['geo_level_2_id'].astype(str) + '_' + X_new['geo_level_3_id'].astype(str)\n",
    "        X_new['geo_all'] = (\n",
    "            X_new['geo_level_1_id'].astype(str) + '_' + \n",
    "            X_new['geo_level_2_id'].astype(str) + '_' +\n",
    "            X_new['geo_level_3_id'].astype(str)\n",
    "        )\n",
    "        # Return the entire dataframe including original and new columns\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "e40ef06e-9560-4fcf-84ab-4769f72f9cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "      <td>240799.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.853758</td>\n",
       "      <td>702.139207</td>\n",
       "      <td>6276.924360</td>\n",
       "      <td>2.053489</td>\n",
       "      <td>25.865037</td>\n",
       "      <td>7.418868</td>\n",
       "      <td>5.160956</td>\n",
       "      <td>0.081072</td>\n",
       "      <td>0.797292</td>\n",
       "      <td>0.035121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024477</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.004842</td>\n",
       "      <td>2.254665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.938389</td>\n",
       "      <td>409.412468</td>\n",
       "      <td>3646.519437</td>\n",
       "      <td>0.624599</td>\n",
       "      <td>72.641948</td>\n",
       "      <td>2.973722</td>\n",
       "      <td>1.460206</td>\n",
       "      <td>0.272946</td>\n",
       "      <td>0.402018</td>\n",
       "      <td>0.184085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154525</td>\n",
       "      <td>0.071057</td>\n",
       "      <td>0.023318</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>0.030621</td>\n",
       "      <td>0.011527</td>\n",
       "      <td>0.009338</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.603874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>3098.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>706.000000</td>\n",
       "      <td>6289.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>9440.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>12567.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>995.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  \\\n",
       "count   240799.000000   240799.000000   240799.000000        240799.000000   \n",
       "mean        13.853758      702.139207     6276.924360             2.053489   \n",
       "std          7.938389      409.412468     3646.519437             0.624599   \n",
       "min          0.000000        0.000000        0.000000             1.000000   \n",
       "25%          7.000000      355.000000     3098.500000             2.000000   \n",
       "50%         12.000000      706.000000     6289.000000             2.000000   \n",
       "75%         21.000000     1050.000000     9440.000000             2.000000   \n",
       "max         30.000000     1427.000000    12567.000000             9.000000   \n",
       "\n",
       "                 age  area_percentage  height_percentage  \\\n",
       "count  240799.000000    240799.000000      240799.000000   \n",
       "mean       25.865037         7.418868           5.160956   \n",
       "std        72.641948         2.973722           1.460206   \n",
       "min         0.000000         1.000000           2.000000   \n",
       "25%        10.000000         5.000000           4.000000   \n",
       "50%        15.000000         7.000000           5.000000   \n",
       "75%        30.000000         9.000000           6.000000   \n",
       "max       995.000000        17.000000           8.000000   \n",
       "\n",
       "       has_superstructure_adobe_mud  has_superstructure_mud_mortar_stone  \\\n",
       "count                 240799.000000                        240799.000000   \n",
       "mean                       0.081072                             0.797292   \n",
       "std                        0.272946                             0.402018   \n",
       "min                        0.000000                             0.000000   \n",
       "25%                        0.000000                             1.000000   \n",
       "50%                        0.000000                             1.000000   \n",
       "75%                        0.000000                             1.000000   \n",
       "max                        1.000000                             1.000000   \n",
       "\n",
       "       has_superstructure_stone_flag  ...  has_secondary_use_hotel  \\\n",
       "count                  240799.000000  ...            240799.000000   \n",
       "mean                        0.035121  ...                 0.024477   \n",
       "std                         0.184085  ...                 0.154525   \n",
       "min                         0.000000  ...                 0.000000   \n",
       "25%                         0.000000  ...                 0.000000   \n",
       "50%                         0.000000  ...                 0.000000   \n",
       "75%                         0.000000  ...                 0.000000   \n",
       "max                         1.000000  ...                 1.000000   \n",
       "\n",
       "       has_secondary_use_rental  has_secondary_use_institution  \\\n",
       "count             240799.000000                  240799.000000   \n",
       "mean                   0.005075                       0.000544   \n",
       "std                    0.071057                       0.023318   \n",
       "min                    0.000000                       0.000000   \n",
       "25%                    0.000000                       0.000000   \n",
       "50%                    0.000000                       0.000000   \n",
       "75%                    0.000000                       0.000000   \n",
       "max                    1.000000                       1.000000   \n",
       "\n",
       "       has_secondary_use_school  has_secondary_use_industry  \\\n",
       "count             240799.000000               240799.000000   \n",
       "mean                   0.000174                    0.000939   \n",
       "std                    0.013206                    0.030621   \n",
       "min                    0.000000                    0.000000   \n",
       "25%                    0.000000                    0.000000   \n",
       "50%                    0.000000                    0.000000   \n",
       "75%                    0.000000                    0.000000   \n",
       "max                    1.000000                    1.000000   \n",
       "\n",
       "       has_secondary_use_health_post  has_secondary_use_gov_office  \\\n",
       "count                  240799.000000                 240799.000000   \n",
       "mean                        0.000133                      0.000087   \n",
       "std                         0.011527                      0.009338   \n",
       "min                         0.000000                      0.000000   \n",
       "25%                         0.000000                      0.000000   \n",
       "50%                         0.000000                      0.000000   \n",
       "75%                         0.000000                      0.000000   \n",
       "max                         1.000000                      1.000000   \n",
       "\n",
       "       has_secondary_use_use_police  has_secondary_use_other   damage_grade  \n",
       "count                 240799.000000            240799.000000  240799.000000  \n",
       "mean                       0.000083                 0.004842       2.254665  \n",
       "std                        0.009113                 0.069417       0.603874  \n",
       "min                        0.000000                 0.000000       1.000000  \n",
       "25%                        0.000000                 0.000000       2.000000  \n",
       "50%                        0.000000                 0.000000       2.000000  \n",
       "75%                        0.000000                 0.000000       3.000000  \n",
       "max                        1.000000                 1.000000       3.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = data.select_dtypes(exclude=['object'])\n",
    "numerical_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "f3567d6b-eff7-4861-ba8f-f1615942fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "def get_right_skewed_columns(df, skew_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Returns the names of columns that are right-skewed based on the skewness value, excluding binary columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: The input DataFrame (numerical columns only).\n",
    "    - skew_threshold: The skewness threshold above which a column is considered right-skewed (default is 0.5).\n",
    "    \n",
    "    Returns:\n",
    "    - List of column names that are right-skewed.\n",
    "    \"\"\"\n",
    "    right_skewed_columns = []\n",
    "    \n",
    "    # Iterate through each column in the dataframe\n",
    "    for col in df.columns:\n",
    "        # Check if the column has more than 2 unique values (to avoid binary columns)\n",
    "        if df[col].nunique() > 2:\n",
    "            # Calculate skewness for each column\n",
    "            col_skewness = skew(df[col].dropna())  # Drop NaN values to avoid issues\n",
    "            \n",
    "            # Check if the skewness is above the specified threshold (indicating right-skewness)\n",
    "            if col_skewness > skew_threshold:\n",
    "                right_skewed_columns.append(col)\n",
    "    \n",
    "    return right_skewed_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "d0f2e52e-cd8a-4bef-b7ee-8203b14255a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right-skewed columns: ['age', 'area_percentage', 'count_families']\n"
     ]
    }
   ],
   "source": [
    "# # Select numerical columns\n",
    "# numerical_df = data.select_dtypes(exclude=['object'])\n",
    "\n",
    "# # Get the right-skewed columns\n",
    "right_skewed_cols = get_right_skewed_columns(numerical_df)\n",
    "\n",
    "print(\"Right-skewed columns:\", right_skewed_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "a3911ffc-6f59-459a-919b-a0331862a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def log_transform(X):\n",
    "    # Apply log1p transformation (log(1 + x)) to avoid issues with zero values\n",
    "    return np.log1p(X)\n",
    "\n",
    "# Create a FunctionTransformer for log transformation\n",
    "log_transformer = FunctionTransformer(log_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "58e3fc36-e7c3-4402-94f1-e6ff2ca0a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# Custom transformer for the age-based transformation\n",
    "class AgeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, age_column='age'):\n",
    "        self.age_column = age_column\n",
    "        self.percentile_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calculate the 99th percentile of the 'age' column and store it\n",
    "        self.percentile_ = np.percentile(X[self.age_column].fillna(np.mean(X[self.age_column])), 99)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        # Add a new 'old' column to indicate if the age exceeds the 99th percentile\n",
    "        X_copy['old'] = np.where(X_copy[self.age_column] >= self.percentile_, 1, 0)\n",
    "        \n",
    "        # Cap the age to 100 where the 'old' column is 1\n",
    "        X_copy.loc[X_copy['old'] == 1, self.age_column] = 100\n",
    "        \n",
    "        return X_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "8ade25df-1961-4cd1-8288-7d019804fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns=['damage_grade'])\n",
    "y = data.damage_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "b8cd2381-4b97-4e93-b311-2de1edc0cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace({1: 0, 2: 1, 3: 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "dba1291f-ff62-40e5-944a-6372b3517406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1         1\n",
       "2         2\n",
       "3         1\n",
       "5         1\n",
       "         ..\n",
       "260596    1\n",
       "260597    2\n",
       "260598    2\n",
       "260599    1\n",
       "260600    2\n",
       "Name: damage_grade, Length: 240799, dtype: int64"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "f1c9c93a-0124-4e52-8c6f-1f0d62805c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_grade\n",
       "1    137372\n",
       "2     82375\n",
       "0     21052\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "f62d6401-05c2-4de0-86e9-9a012300ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.old.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "0243ff84-fb14-4ecb-a5cf-953277152a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical_df = data.select_dtypes(exclude=['object'])\n",
    "#categorical_df = data.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "ca1d5990-7836-4ff9-9cdf-689ddc2445c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in x.columns if  x[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in x.columns if x[cname].dtype in ['int32', 'int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "83ebf2c7-490c-43b9-811f-3c2d149b9f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['land_surface_condition',\n",
       " 'foundation_type',\n",
       " 'roof_type',\n",
       " 'ground_floor_type',\n",
       " 'other_floor_type',\n",
       " 'position',\n",
       " 'plan_configuration',\n",
       " 'legal_ownership_status']"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "1b4ea3f2-1ccf-462f-b581-c21426c40fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(numerical_df.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "712173a0-97d3-4475-b68f-a303af290e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,StandardScaler, MinMaxScaler\n",
    "\n",
    "#train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "5390eb12-6721-40bc-a3e9-f60d922a8323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_grade\n",
       "1    96394\n",
       "2    57400\n",
       "0    14765\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "aca1c3dc-856a-47b7-8258-2657b4318b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "damage_grade\n",
       "1    40978\n",
       "2    24975\n",
       "0     6287\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ca8125c8-9a46-4a44-b21d-d48ce2f8478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import BaseNEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "dddedeba-4ffe-4e0e-a8b8-ce15fe7864a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class SuperstructureFeatureTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom transformer to split superstructure-related columns into new features \n",
    "    like 'has_stone', 'has_brick', 'has_mortar', 'has_cement', and 'has_mud'.\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        # Create the new \"has_stone\" feature\n",
    "        X_copy['has_stone'] = (\n",
    "            X_copy['has_superstructure_mud_mortar_stone'] | \n",
    "            X_copy['has_superstructure_stone_flag'] | \n",
    "            X_copy['has_superstructure_cement_mortar_stone']\n",
    "        )\n",
    "        \n",
    "        # Create the new \"has_brick\" feature\n",
    "        X_copy['has_brick'] = (\n",
    "            X_copy['has_superstructure_mud_mortar_brick'] | \n",
    "            X_copy['has_superstructure_cement_mortar_brick']\n",
    "        )\n",
    "        \n",
    "        # Create the new \"has_adobe_mud\" feature\n",
    "        #X_copy['has_adobe_mud'] = X_copy['has_superstructure_adobe_mud']\n",
    "        \n",
    "        # Create the new \"has_mortar\" feature\n",
    "        X_copy['has_mortar'] = (\n",
    "            X_copy['has_superstructure_mud_mortar_stone'] | \n",
    "            X_copy['has_superstructure_mud_mortar_brick']\n",
    "        )\n",
    "        \n",
    "        # Create the new \"has_cement\" feature\n",
    "        X_copy['has_cement'] = (\n",
    "            X_copy['has_superstructure_cement_mortar_stone'] | \n",
    "            X_copy['has_superstructure_cement_mortar_brick']\n",
    "        )\n",
    "        \n",
    "        # Create the new \"has_mud\" feature\n",
    "        X_copy['has_mud'] = (\n",
    "            X_copy['has_superstructure_mud_mortar_stone'] | \n",
    "            X_copy['has_superstructure_mud_mortar_brick'] | \n",
    "            X_copy['has_superstructure_adobe_mud']\n",
    "        )\n",
    "        \n",
    "        return X_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "ffc2a3a0-b3d2-49f0-90c6-4474abe506e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create numerical transformer\n",
    "geo_interaction_transformer = GeoInteractionTransformer()\n",
    "\n",
    "geo_cols = ['geo1_geo2', 'geo1_geo3', 'geo2_geo3', 'geo_all']\n",
    "\n",
    "# # # BaseNEncoder for the high cardinality of interaction features\n",
    "base_encoder_geo = BaseNEncoder(cols=geo_cols, base=5)\n",
    "\n",
    "# # Geo interaction pipeline: First, create interaction terms, then encode them\n",
    "geo_interaction_pipeline = Pipeline(steps=[\n",
    "     ('geo_interaction', geo_interaction_transformer),  # Create interaction terms\n",
    "     ('base_encoder', base_encoder_geo)  # Encode interaction terms\n",
    "])\n",
    "\n",
    "\n",
    "# numerical_transformer = Pipeline([('imputer', SimpleImputer(strategy='mean'))])\n",
    "\n",
    "# #create categorical transformer\n",
    "# #categorical_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "# #                                            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "# #                                            ])\n",
    "\n",
    "#reduction_columns = ['geo_level_1_id', 'geo_level_2_id','geo_level_3_id']\n",
    "\n",
    "\n",
    "# base_encoder = Pipeline(steps=[\n",
    "#     ('base_encoder', BaseNEncoder(cols=reduction_columns, base=3))\n",
    "# ])\n",
    "\n",
    "# age_transformer = Pipeline(steps=[\n",
    "#     ('age_transform', AgeTransformer(age_column='age'))  # Apply age transformation\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4328c-afab-40e1-a982-c79bb93326ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "a685d12c-939f-45de-accb-b8ba4b0d4149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id',\n",
       "       'count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage',\n",
       "       'land_surface_condition', 'foundation_type', 'roof_type',\n",
       "       'ground_floor_type', 'other_floor_type', 'position',\n",
       "       'plan_configuration', 'has_superstructure_adobe_mud',\n",
       "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
       "       'has_superstructure_cement_mortar_stone',\n",
       "       'has_superstructure_mud_mortar_brick',\n",
       "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
       "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
       "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
       "       'legal_ownership_status', 'count_families', 'has_secondary_use',\n",
       "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
       "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
       "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
       "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
       "       'has_secondary_use_use_police', 'has_secondary_use_other',\n",
       "       'damage_grade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28baa678-8ef1-48cc-91d3-8404ef8e4833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "f012f605-662e-471c-9a22-14c4f55a2ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Define the autoencoder class\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "        # Decoder (optional, only necessary if you want reconstruction)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "# Custom transformer to handle autoencoder training and dimensionality reduction\n",
    "class AutoencoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, latent_dim=10, epochs=100, batch_size=32, learning_rate=1e-3):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.autoencoder = None  # Autoencoder model will be initialized in `fit`\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Automatically determine input_dim based on X's shape after BaseN encoding\n",
    "        input_dim = X.shape[1]  # Number of features in X after BaseN encoding\n",
    "        self.autoencoder = Autoencoder(input_dim=input_dim, latent_dim=self.latent_dim)\n",
    "\n",
    "        # Convert X to NumPy array if it's a DataFrame\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)  # Convert NumPy array to tensor\n",
    "        optimizer = torch.optim.Adam(self.autoencoder.parameters(), lr=self.learning_rate)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            encoded, decoded = self.autoencoder(X_tensor)\n",
    "            loss = criterion(decoded, X_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % 10 == 0:  # Print loss every 10 epochs for monitoring\n",
    "                print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "                \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Convert X to NumPy array if it's a DataFrame\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "\n",
    "        self.autoencoder.eval()  # Set to evaluation mode\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)  # Convert NumPy array to tensor\n",
    "        with torch.no_grad():\n",
    "            encoded, _ = self.autoencoder(X_tensor)\n",
    "        return encoded.numpy()  # Return the reduced-dimensional representation\n",
    "\n",
    "\n",
    "reduction_columns = ['geo_level_1_id', 'geo_level_2_id','geo_level_3_id']\n",
    "\n",
    "base_encoder_columns = ['land_surface_condition',\n",
    " 'foundation_type',\n",
    " 'roof_type',\n",
    " 'ground_floor_type',\n",
    " 'other_floor_type',\n",
    " 'position',\n",
    " 'plan_configuration',\n",
    " 'legal_ownership_status']\n",
    "\n",
    "base_encoder = Pipeline(steps=[\n",
    "    ('base_encoder', BaseNEncoder(cols=base_encoder_columns, base=3))\n",
    "])\n",
    "\n",
    "base_encoder_geo = Pipeline(steps=[\n",
    "    ('base_encoder', BaseNEncoder(cols=reduction_columns, base=3))\n",
    "])\n",
    "\n",
    "# Define the pipeline with an Autoencoder for dimensionality reduction\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "\n",
    "    ('base_name_geo', base_encoder_geo, reduction_columns),  # BaseN encoding on categorical columns\n",
    "\n",
    "    # Autoencoder dimensionality reduction for BaseN encoded features\n",
    "    ('autoencoder', Pipeline(steps=[\n",
    "        ('extractor', FunctionTransformer(lambda x: x, feature_names_out='one-to-one')),  # Pass through BaseN encoded features\n",
    "        ('autoencoder', AutoencoderTransformer(latent_dim=5))  # Autoencoder with latent dimension 10\n",
    "    ]), reduction_columns),\n",
    "    # ('autoencoder', Pipeline(steps=[\n",
    "    #     ('extractor', FunctionTransformer(lambda x: x, feature_names_out='one-to-one')),  # Extract original geo columns\n",
    "    #     ('autoencoder', AutoencoderTransformer(latent_dim=5))  # Autoencoder for geo features with latent dimension 5\n",
    "    # ]), reduction_columns),\n",
    "\n",
    "    ('base_name', base_encoder, base_encoder_columns),  # BaseN encoding on categorical columns\n",
    "    ('age_transform', age_transformer, ['age']),  # Custom transformer for 'age'\n",
    "    ('num', 'passthrough', numerical_cols),  # Pass through numerical columns without transformation\n",
    "    ('log_transform', log_transformer, right_skewed_cols)  # Log transform for right-skewed columns\n",
    "    # Add other transformers or steps as needed\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "11e7bafb-8201-4fcc-b2c3-1f662ed14fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the pipeline with an Autoencoder replacing PCA\n",
    "# preprocessor = ColumnTransformer(transformers=[\n",
    "#     ('base_name', base_encoder, base_encoder_columns),  # BaseN encoding on categorical columns\n",
    "\n",
    "#     # Autoencoder dimensionality reduction for BaseN encoded features\n",
    "#     ('autoencoder', Pipeline(steps=[\n",
    "#         ('extractor', FunctionTransformer(lambda x: x, feature_names_out='one-to-one')),  # Extract BaseN encoded features\n",
    "#         ('autoencoder', AutoencoderTransformer(input_dim=15, latent_dim=10))  # Adjust input_dim to match BaseN output\n",
    "#     ]), base_encoder_columns),\n",
    "\n",
    "#     ('age_transform', age_transformer, ['age']),  # Custom transformer for 'age'\n",
    "#     ('num', 'passthrough', numerical_cols),  # Pass through numerical columns without transformation\n",
    "#     ('log_transform', log_transformer, right_skewed_cols)  # Log transform for right-skewed columns\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "c3af85d6-3871-4f19-a54c-1daf5d2a8963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 19167194.0\n",
      "Epoch 10, Loss: 15490962.0\n",
      "Epoch 20, Loss: 9518197.0\n",
      "Epoch 30, Loss: 2524483.75\n",
      "Epoch 40, Loss: 303220.125\n",
      "Epoch 50, Loss: 407640.03125\n",
      "Epoch 60, Loss: 122995.921875\n",
      "Epoch 70, Loss: 114088.3046875\n",
      "Epoch 80, Loss: 57516.64453125\n",
      "Epoch 90, Loss: 31230.220703125\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.455101924325866, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.455101924325866\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007915220427757011, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007915220427757011\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.455101924325866, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.455101924325866\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007915220427757011, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007915220427757011\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2114\n",
      "[LightGBM] [Info] Number of data points in the train set: 168559, number of used features: 74\n",
      "[LightGBM] [Info] Start training from score -2.435026\n",
      "[LightGBM] [Info] Start training from score -0.558842\n",
      "[LightGBM] [Info] Start training from score -1.077242\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=7.455101924325866, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.455101924325866\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007915220427757011, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007915220427757011\n",
      "Accuracy for XGBoost: 0.7463178294573644\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57      6287\n",
      "           1       0.75      0.85      0.79     40978\n",
      "           2       0.76      0.64      0.70     24975\n",
      "\n",
      "    accuracy                           0.75     72240\n",
      "   macro avg       0.73      0.66      0.69     72240\n",
      "weighted avg       0.75      0.75      0.74     72240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# LightGBM for Multiclass Classification\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=843,\n",
    "    learning_rate=0.16934236113095621,\n",
    "    max_depth=7,\n",
    "    random_state=42,\n",
    "    lambda_l1=7.455101924325866,  # L2 regularization\n",
    "    lambda_l2=0.007915220427757011,\n",
    "    subsample=0.7354468519750788,    # Subsample ratio of the training instances\n",
    "    colsample_bytree=0.8648222301238216,           # Subsample ratio of columns when constructing each tree\n",
    "    min_child_weight=2,             # Equivalent of min_data_in_leaf in LightGBM\n",
    "    subsample_for_bin=200000,\n",
    "    num_leaves=31,\n",
    "    #reg_alpha=0.14170716330946964,  # L1 regularization term\n",
    "    objective='multiclass',         # Objective for multiclass classification\n",
    "    metric='multi_logloss',         # Metric used for multiclass classification\n",
    "    num_class=3                     # Specify the number of classes in the target\n",
    ")\n",
    "\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # Step 1: Preprocessing\n",
    "    ('xgboost', lgbm)  # Step 3: Model training\n",
    "])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "#rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of training data, fit model after upsampling!\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "rf_preds = rf_pipe.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, rf_preds)\n",
    "print('Accuracy for XGBoost:', accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print('Classification Report:\\n', classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "b691816d-f987-4490-a12b-e7ee7266b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     'preprocessor__autoencoder__autoencoder__latent_dim': [5, 10, 15, 20]  # Testing different latent_dim values\n",
    "# }\n",
    "\n",
    "# # Create a grid search\n",
    "# grid_search = GridSearchCV(rf_pipe, param_grid, cv=3)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best latent_dim\n",
    "# best_latent_dim = grid_search.best_params_['preprocessor__autoencoder__autoencoder__latent_dim']\n",
    "# print(f'Best latent_dim: {best_latent_dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "17c7ee6b-4d40-4c75-8673-fb68368f83b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 17895082.0\n",
      "Epoch 10, Loss: 10108766.0\n",
      "Epoch 20, Loss: 2132321.25\n",
      "Epoch 30, Loss: 528997.9375\n",
      "Epoch 40, Loss: 304072.46875\n",
      "Epoch 50, Loss: 179036.859375\n",
      "Epoch 60, Loss: 94923.5546875\n",
      "Epoch 70, Loss: 79697.3828125\n",
      "Epoch 80, Loss: 52537.9140625\n",
      "Epoch 90, Loss: 42737.546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for XGBoost: 0.7441860465116279\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57      6287\n",
      "           1       0.74      0.85      0.79     40978\n",
      "           2       0.76      0.64      0.69     24975\n",
      "\n",
      "    accuracy                           0.74     72240\n",
      "   macro avg       0.73      0.66      0.69     72240\n",
      "weighted avg       0.74      0.74      0.74     72240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# from xgboost import XGBClassifier\n",
    "# # XGBoost\n",
    "# xgb = XGBClassifier(\n",
    "#     n_estimators=600,\n",
    "#     learning_rate=0.2669112505018992,\n",
    "#     max_depth=5,\n",
    "#     random_state=42,\n",
    "#     reg_lambda=1.2259716591605452,\n",
    "#     subsample=0.704976942819638,\n",
    "#     colsample_bytree=0.9,\n",
    "#     min_child_weight=4,\n",
    "#     alpha= 0.14170716330946964,    # Added L1 regularization\n",
    "#     eval_metric='mlogloss',  # Consider custom loss for ordinal\n",
    "#     objective='multi:softmax',  # Using softmax but can tweak for ordinal\n",
    "#     num_class=3  # Assuming 3 ordinal classes\n",
    "# )\n",
    "\n",
    "# rf_pipe = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),  # Step 1: Preprocessing\n",
    "#     ('xgboost', xgb)  # Step 3: Model training\n",
    "# ])\n",
    "\n",
    "# # Preprocessing of training data, fit model \n",
    "# #rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# # Preprocessing of training data, fit model after upsampling!\n",
    "# rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# # Preprocessing of validation data, get predictions\n",
    "# rf_preds = rf_pipe.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, rf_preds)\n",
    "# print('Accuracy for XGBoost:', accuracy)\n",
    "\n",
    "# # Detailed classification report\n",
    "# print('Classification Report:\\n', classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "d64ed6c4-ad09-4587-9fd8-6430598e11a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: lamda_l2\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.455101924325866, reg_alpha=0.14170716330946964 will be ignored. Current value: lambda_l1=7.455101924325866\n",
      "Accuracy for XGBoost: 0.7974833737741681\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.60      0.69     14765\n",
      "           1       0.79      0.89      0.84     96394\n",
      "           2       0.82      0.69      0.75     57400\n",
      "\n",
      "    accuracy                           0.80    168559\n",
      "   macro avg       0.80      0.73      0.76    168559\n",
      "weighted avg       0.80      0.80      0.79    168559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing of validation data, get predictions\n",
    "rf_preds = rf_pipe.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_train, rf_preds)\n",
    "print('Accuracy for XGBoost:', accuracy)\n",
    "\n",
    "# Detailed classification report\n",
    "print('Classification Report:\\n', classification_report(y_train, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "daeb6fd1-1fb3-4479-8978-2a38fc3f9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/raw/test_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "dafbc507-fb2c-4ad2-8134-70d35d158954",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_final = test_data.building_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "730a579f-3081-41a2-85ae-7ebc758060d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         300051\n",
       "1          99355\n",
       "2         890251\n",
       "3         745817\n",
       "4         421793\n",
       "          ...   \n",
       "86863     310028\n",
       "86864     663567\n",
       "86865    1049160\n",
       "86866     442785\n",
       "86867     501372\n",
       "Name: building_id, Length: 86868, dtype: int64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "b8315b74-c8b7-46a7-8bf9-e92323217a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=7.455101924325866, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.455101924325866\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007915220427757011, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007915220427757011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        1\n",
       "2        1\n",
       "3        0\n",
       "4        2\n",
       "        ..\n",
       "86863    1\n",
       "86864    2\n",
       "86865    1\n",
       "86866    1\n",
       "86867    0\n",
       "Length: 86868, dtype: int64"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_preds = rf_pipe.predict(test_data)\n",
    "rf_preds = pd.Series(rf_preds)\n",
    "rf_preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "80bebbfa-d40f-41b9-9103-a3dfca239303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated = pd.concat([X_test_final, rf_preds], axis=1)\n",
    "df_concatenated\n",
    "df_concatenated = df_concatenated.rename(columns={0: 'damage_grade'})\n",
    "df_concatenated\n",
    "df_concatenated['damage_grade'] = df_concatenated['damage_grade'].replace({0: 1, 1: 2, 2: 3})\n",
    "df_concatenated.to_csv('../data/processed/RLsub1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28226e9-3c26-44cb-beda-9c50233aadc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
